{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the trained tflite model on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If everything works, then output should be something like the image below.\n",
    "# However, the tflite-model-maker used for this project used many \n",
    "# old packages, so version conflicts are likely during installation. So\n",
    "# it's probably best to start from scratch with a current object detection\n",
    "# library.\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "plt.figure(figsize=(8,8))\n",
    "img=mpimg.imread('car-white-pred.png') # carotene and white colonies\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cryptography --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T11:21:11.419231Z",
     "iopub.status.busy": "2021-05-17T11:21:11.418690Z",
     "iopub.status.idle": "2021-05-17T11:21:30.029068Z",
     "shell.execute_reply": "2021-05-17T11:21:30.029484Z"
    },
    "id": "qhl8lqVamEty"
   },
   "outputs": [],
   "source": [
    "#!pip install tflite-model-maker\n",
    "#!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-addons\n",
    "#!pip install opencv-python\n",
    "#!pip install tflite_model_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T11:21:30.034632Z",
     "iopub.status.busy": "2021-05-17T11:21:30.034032Z",
     "iopub.status.idle": "2021-05-17T11:21:38.196658Z",
     "shell.execute_reply": "2021-05-17T11:21:38.197054Z"
    },
    "id": "XtxiUeZEiXpt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "!python --version\n",
    "tf.__version__\n",
    "#!conda env list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T11:21:39.471257Z",
     "iopub.status.busy": "2021-05-17T11:21:39.470332Z",
     "iopub.status.idle": "2021-05-17T11:21:39.472714Z",
     "shell.execute_reply": "2021-05-17T11:21:39.473050Z"
    },
    "id": "CtdZ-JDwMimd"
   },
   "outputs": [],
   "source": [
    "spec = model_spec.get('efficientdet_lite1')\n",
    "spec.config.num_classes=2              # carotene (orange), white\n",
    "spec.config.tflite_max_detections=100  # <<< default is 100\n",
    "spec.config.label_map={1: \"car\", 2: \"white\"} \n",
    "#print(spec.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall opencv-python-headless==4.5.5.62 --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-05-17T11:36:45.084671Z",
     "iopub.status.busy": "2021-05-17T11:36:45.084089Z",
     "iopub.status.idle": "2021-05-17T11:36:45.543186Z",
     "shell.execute_reply": "2021-05-17T11:36:45.542659Z"
    },
    "id": "XqS0rFCrqM1o"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Load the labels into a list\n",
    "classes = ['???'] * spec.config.num_classes\n",
    "label_map = spec.config.label_map\n",
    "for label_id, label_name in label_map.as_dict().items():\n",
    "    classes[label_id-1] = label_name\n",
    "\n",
    "\n",
    "# Define a list of colors for visualization\n",
    "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
    "\n",
    "def preprocess_image(image_path, input_size):\n",
    "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
    "  img = tf.io.read_file(image_path)\n",
    "  img = tf.io.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "  original_image = img\n",
    "  resized_img = tf.image.resize(img, input_size)\n",
    "  resized_img = resized_img[tf.newaxis, :]\n",
    "  return resized_img, original_image\n",
    "\n",
    "\n",
    "def set_input_tensor(interpreter, image):\n",
    "  \"\"\"Set the input tensor.\"\"\"\n",
    "  tensor_index = interpreter.get_input_details()[0]['index']\n",
    "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "  input_tensor[:, :] = image\n",
    "\n",
    "\n",
    "def get_output_tensor(interpreter, index):\n",
    "  \"\"\"Return the output tensor at the given index.\"\"\"\n",
    "  output_details = interpreter.get_output_details()[index]\n",
    "  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
    "  return tensor\n",
    "\n",
    "\n",
    "# A high confidence threshold will prevent most overlaps, but not all.\n",
    "# boxes_overlap was designed to prevent the same colony from being detected more \n",
    "# once.\n",
    "def boxes_overlap(ymin1, xmin1, ymax1, xmax1, ymin2, xmin2, ymax2, xmax2, IOU_threshold):\n",
    "    \n",
    "   # if (xmin1 == xmin2 or ymin1 == ymin2 or xmax1 == xmax2 or ymax1 == ymax2):\n",
    "   #    # the line cannot have positive overlap\n",
    "   #     return False\n",
    "         \n",
    "    # If one rectangle is on left side of other\n",
    "    if(xmin1 >= xmax2 or xmax1 <= xmin2):\n",
    "        return False\n",
    " \n",
    "    # If one rectangle is above other\n",
    "    if(ymax1 <= ymin2 or ymax2 <= ymin1):\n",
    "        return False\n",
    "    \n",
    "    XA1=xmin1;  XA2=xmax1;   YA1=ymin1;   YA2=ymax2;\n",
    "    XB1=xmin2;  XB2=xmax2;   YB1=ymin2;   YB2=ymax2\n",
    "    \n",
    "    SA = (XA2 - XA1) * (YA2 - YA1)\n",
    "    SB = (XB2 - XB1) * (YB2 - YB1)\n",
    "    \n",
    "    SI = max(0, min(XA2, XB2) - max(XA1, XB1)) * max(0, min(YA2, YB2) - max(YA1, YB1))\n",
    "\n",
    "    pct_overlap = SI/(SA+SB)   # intersection/union\n",
    "\n",
    "    if pct_overlap <= IOU_threshold:\n",
    "        return False\n",
    "        \n",
    "    #print(f\"The two bounding boxes overlap is {pct_overlap}\")\n",
    " \n",
    "    return True\n",
    "\n",
    "\n",
    "# Puts list of results in ascending order by score\n",
    "# Returns true if two rectangles overlap\n",
    "def filter_results(results, bb_threshold):\n",
    "\n",
    "    results_filtered = []  #{'bounding_box':[], 'score':0, 'class_id': 0 }\n",
    "    \n",
    "    mylist =[]\n",
    "    for ii in range(len(results)):\n",
    "        mylist.append(results[ii]['score'])\n",
    "\n",
    "    mylist=np.array(mylist)\n",
    "    idx = np.argsort(mylist*-1)  # want desceding order, == reverse\n",
    "\n",
    "    results_sorted = []\n",
    "    for ii in idx:\n",
    "        results_sorted.append(results[ii])\n",
    "        \n",
    "    results = results_sorted   \n",
    "    \n",
    "    #verify order    \n",
    "#     for ii in range(len(results)):\n",
    "#         print(results[ii]['score'])\n",
    "    \n",
    "    for ii in range( len(results) ):\n",
    "        ymin1, xmin1, ymax1, xmax1 = results[ii]['bounding_box']\n",
    "        overlap=False\n",
    "        \n",
    "        for jj in range(len(results) ):\n",
    "            if ii==jj:\n",
    "                continue\n",
    "        \n",
    "            ymin2, xmin2, ymax2, xmax2 = results[jj]['bounding_box']\n",
    "            \n",
    "            if boxes_overlap(ymin1, xmin1, ymax1, xmax1, ymin2, xmin2, ymax2, xmax2, bb_threshold)\\\n",
    "                and results[ii]['score'] <= results[jj]['score']:\n",
    "                    overlap=True\n",
    "                    break\n",
    "\n",
    "            \n",
    "        if overlap == False:    \n",
    "            results_filtered.append(results[ii])  # for cases of overlap, this box had highest score\n",
    "                  \n",
    "    return results_filtered\n",
    "\n",
    "\n",
    "\n",
    "def detect_objects(interpreter, image, confidence_threshold):\n",
    "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
    "  # Feed the input image to the model\n",
    "  set_input_tensor(interpreter, image)\n",
    "  interpreter.invoke()\n",
    "\n",
    "  ###################################################################################################\n",
    "  # Get all outputs from the model, NOTE the indices might be different for a different model.tflite \n",
    "  # that's odd, but that was the fix\n",
    "  ####################################################################################################\n",
    "  boxes = get_output_tensor(interpreter, 1)\n",
    "  classes = get_output_tensor(interpreter, 3)\n",
    "  scores = get_output_tensor(interpreter, 0)\n",
    "  count = int(get_output_tensor(interpreter, 2))\n",
    "\n",
    "\n",
    "  print(\">>\", scores.size)\n",
    "\n",
    "\n",
    "  results = []\n",
    "  for i in range(scores.size):\n",
    "    if scores[i] >= confidence_threshold:\n",
    "      result = {\n",
    "        'bounding_box': boxes[i],\n",
    "        'class_id': classes[i],\n",
    "        'score': scores[i]\n",
    "      }\n",
    "      results.append(result)\n",
    "        \n",
    "  print('first box: ', boxes[0])\n",
    "  print('result count: ', len(results))\n",
    "    \n",
    "  return results\n",
    "\n",
    "\n",
    "\n",
    "def run_odt_and_draw_results(image_path, interpreter, filter_boolean, confidence_threshold, IOU_threshold):\n",
    "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
    "  # Load the input shape required by the model\n",
    "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
    "\n",
    "  # Load the input image and preprocess it\n",
    "  preprocessed_image, original_image = preprocess_image(image_path,\n",
    "      (input_height, input_width)\n",
    "    )\n",
    "    \n",
    "  # Run object detection on the input image\n",
    "  results = detect_objects(interpreter, preprocessed_image, confidence_threshold)\n",
    "\n",
    "#   if len(results) == 0:\n",
    "#     print(\"no results\")\n",
    "#     return (preprocessed_image, original_uint8)\n",
    "    \n",
    "  if filter_boolean:\n",
    "    print(\"filtering=True\")\n",
    "    results = filter_results(results, IOU_threshold)\n",
    "    \n",
    "  print(\"length of filtered results: \", len(results))\n",
    "\n",
    "  # Plot the detection results on the input image\n",
    "  original_image_np = original_image.numpy().astype(np.uint8)\n",
    "\n",
    "  for obj in results:\n",
    "    # Convert the object bounding box from relative coordinates to absolute\n",
    "    # coordinates based on the original image resolution\n",
    "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
    "    xmin = int(xmin * original_image_np.shape[1])\n",
    "    xmax = int(xmax * original_image_np.shape[1])\n",
    "    ymin = int(ymin * original_image_np.shape[0])\n",
    "    ymax = int(ymax * original_image_np.shape[0])\n",
    "    \n",
    "    print(\"ymin,xmin,ymax,xmax:\", ymin,xmin,ymax,xmax )\n",
    "    \n",
    "    if xmin > xmax:\n",
    "        print(\"xmin > xmax\")\n",
    "            \n",
    "    if ymin > ymax:\n",
    "        print(\"ymin > ymax\")\n",
    "    \n",
    "    if abs(xmax - xmin) < 1 or abs(ymax-ymin) < 1: # too small to be a valid colony\n",
    "        continue\n",
    "\n",
    "    ## for debugging\n",
    "    #print(obj['score'] * 100, \"==>\", xmin,xmax,ymin,ymax,\"\\n\")\n",
    "\n",
    "    # Find the class index of the current object\n",
    "    class_id = int(obj['class_id'])\n",
    "    #print(class_id) # 0, 1, ...\n",
    "\n",
    "    # Draw the bounding box and label on the image\n",
    "    color = 1 # [int(c) for c in COLORS[class_id]]\n",
    "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 1)\n",
    "    # Make adjustments to make the label visible for all objects\n",
    "    if (ymin - 7) > 10: \n",
    "        y = ymin - 7     \n",
    "    else: \n",
    "        y = ymin + 40\n",
    "        \n",
    "        \n",
    "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
    "\n",
    "    #label = \"{}: {:.0f}%\".format('col', obj['score'] * 100)\n",
    "    \n",
    "    cv2.putText(original_image_np, label, (xmin, y), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.85, color, 2)\n",
    "\n",
    "  # Return the final image\n",
    "  original_uint8 = original_image_np.astype(np.uint8)\n",
    "  return (preprocessed_image, original_uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_rotate_images.py  04_norm_coords_and_format.py  images-26-orange-white\r\n",
      "02_label_to_csv.py   images-25-26-orange-white\r\n",
      "03_rotate_boxes.py   images-25-orange-white\r\n"
     ]
    }
   ],
   "source": [
    "!ls data-set-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.jpg\t\t\t     img_2021-08-25_16-48-12.jpg\r\n",
      "270.jpg\t\t\t     img_2021-08-26_15-48-28.jpg\r\n",
      "90.jpg\t\t\t     img_2021-08-26_15-50-13.jpg\r\n",
      "img_2021-08-25_16-47-08.jpg  img_2021-08-26_15-52-08.jpg\r\n",
      "img_2021-08-25_16-47-42.jpg  img_2021-08-26_15-52-42.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls data-set-maker/images-25-26-orange-white/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_data, validation_data, test_data = object_detector.DataLoader.from_csv('train_labels-normed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate to get each test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-05-17T11:36:45.642063Z",
     "iopub.status.busy": "2021-05-17T11:36:45.641322Z",
     "iopub.status.idle": "2021-05-17T11:36:48.620210Z",
     "shell.execute_reply": "2021-05-17T11:36:48.620597Z"
    },
    "id": "GkXtipXKqXp4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-set-maker/images-25-26-orange-white/test/90.jpg \n",
      "\n",
      ">> 100\n",
      "first box:  [0.50275904 0.94787407 0.5587607  0.998448  ]\n",
      "result count:  24\n",
      "filtering=True\n",
      "length of filtered results:  7\n",
      "ymin,xmin,ymax,xmax: 804 1516 894 1597\n",
      "ymin,xmin,ymax,xmax: 906 1045 985 1124\n",
      "ymin,xmin,ymax,xmax: 576 1402 662 1492\n",
      "ymin,xmin,ymax,xmax: 274 1174 355 1258\n",
      "ymin,xmin,ymax,xmax: 573 1208 656 1293\n",
      "ymin,xmin,ymax,xmax: 512 1014 591 1093\n",
      "ymin,xmin,ymax,xmax: 443 1241 522 1322\n"
     ]
    }
   ],
   "source": [
    "#@title Run object detection and show the detection results\n",
    "\n",
    "# If trained using only a small number of epochs (~5 or 10), classification will be bad, \n",
    "# probably need between 50 and 100 epochs (100 takes about 1 hour?).\n",
    "\n",
    "# If more training, can set the detection (confidence) threshold higher than 0.15.\n",
    "# Basically, there is a trade-off between true positives and false positives, etc.\n",
    "#\n",
    "\n",
    "IOU_threshold=0.10        # intersection/union\n",
    "confidence_threshold=0.10 # <<<<<<<<<<<================== confidence!\n",
    "filter_boolean=True       # <<<<<<<<<<<================== excludes ovelapping boxes\n",
    "\n",
    "test_folder=\"data-set-maker/images-25-26-orange-white/test/\"\n",
    "\n",
    "test_files= os.listdir(test_folder)\n",
    "\n",
    "test_path= test_folder + test_files[2]  # <<<=================== choose test file\n",
    "\n",
    "print(test_path, \"\\n\")\n",
    "\n",
    "model_path = 'model_50.tflite'      # <<<==== using trained model, but check this\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Run inference and draw detection result on the local copy of the original file\n",
    "(preprocessed_image, detection_result_image) = run_odt_and_draw_results(\n",
    "    test_path,\n",
    "    interpreter,\n",
    "    filter_boolean,\n",
    "    confidence_threshold,\n",
    "    IOU_threshold\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=preprocessed_image[0,:,:,:]/255\n",
    "#temp=plt.imshow(img)\n",
    "#print(type(img))\n",
    "#tf.keras.preprocessing.image.save_img('temp.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the detection result\n",
    "\n",
    "#result_img=Image.fromarray(detection_result_image)\n",
    "#plt.figure(figsize=(10,10))\n",
    "#temp=plt.imshow(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_img.save(\"car-white-2.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model Maker Object Detection Tutorial",
   "provenance": [
    {
     "file_id": "1dbRXQCjtm-jBFC32DJ6YCVXnXBOG3M5t",
     "timestamp": 1613441434239
    },
    {
     "file_id": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_text_classification.ipynb",
     "timestamp": 1612303859066
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
